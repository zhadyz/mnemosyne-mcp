# Embedding Provider Configuration
# Options: 'auto' (default), 'local', 'openai'
# - 'auto': Uses OpenAI if API key is present, otherwise falls back to local embeddings
# - 'local': Always use local ONNX-based embeddings (free, no API key required)
# - 'openai': Always use OpenAI embeddings (requires API key)
EMBEDDING_PROVIDER=auto

# Local Embedding Model (used when EMBEDDING_PROVIDER=local or as fallback)
# Supported models:
# - Xenova/bge-base-en-v1.5 (768 dimensions, default, ~90MB)
# - Xenova/bge-small-en-v1.5 (384 dimensions, ~30MB)
# - Xenova/bge-large-en-v1.5 (1024 dimensions, ~200MB)
# - Xenova/bge-m3 (1024 dimensions, multilingual, ~200MB)
LOCAL_EMBEDDING_MODEL=Xenova/bge-base-en-v1.5

# OpenAI Configuration (only needed if EMBEDDING_PROVIDER=openai)
# Tests will mock embedding generation if no API key is provided.
# To run tests with real embeddings (recommended), rename this file to .env with your OpenAI API key.
OPENAI_API_KEY=your-openai-api-key
# Default OpenAI embedding model
OPENAI_EMBEDDING_MODEL=text-embedding-3-small